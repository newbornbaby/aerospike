# 1.简介
aerospike是高效的nosql数据库，采用纯内存或者内存+ssd方案存储数据，设计初衷达到了以下三个主要目的：
数据的快速、高效存取。
提供传统数据库的可靠性、健壮性、ACID能力。
灵活性、扩展性、容错能力。
2.架构设计
as采用share nothing设计模式，在各个处理单元中使用自己私有的cpu以及memory，不存在共享资源，类似于MMP（大规模并行处理）模式，各处理单元之间通过协议通信，并行处理和扩展能力强（典型的类似案例还有hadoop等），各节点处理完数据后，处理结果可以向上层汇总，或者在节点之间流转；此外，as的架构设计主要可以分为三层：
Client Layer（客户端）层：实现as API，直接与集群通信、跟踪节点，发现节点的上下线、知道数据在节点中的位置。
Clustering and Data Distribution Layer（集群和数据分发）层：管理集群、自动故障转移、高效分配任务、智能平衡数据、自动数据备份、数据迁移、跨数据中心同步数据。
Data Storage Layer（数据存储）层：可靠地将数据存储到DRAM与FLASH中。 ￼ as架构设计图
3.详细设计
3.1 Distribution Layer：
分发层旨在通过系统自动化所有集群管理功能，来最大程度的消除手动操作，该层有三个重要模块：
3.1.1 Cluster Managerment Module（集群管理模块）：
重点：通过Paxos-base gossip-voting process算法来确认集群内节点，使集群中所有节点对当前集群成员身份达成一致（Paxos是一中在分布式设计中广泛使用的分布式一致性协议），同时通过heartbeat监控各个节点的状态。
Cluster View（集群视图）：集群中的每一个一个node都会注册一个identifier，有涉及mac以及port的一个算法产生；集群视图由标识，其中cluster_key是一个8位的随机数，succession_list是集群成员标识符集合，当集群成员状态发生变动时，会产生一个新的cluster_key以及对应的succession_list，来标识新视图；由于每次成员变动都会影响集群重新配置视图，导致处理延迟和处理效率下降，所以有必要使用一个一致性机制，快速有效地使集群重新达到一致状态。
Cluster Discovery：集群中的每个node通过向其他节点周期性地持续地发送心跳包来告诉其他节点自己的状态，每个节点维护一份存活着的node列表，里面记录了会向这个节点发送消息的其他节点的标识，心跳时间吐过超过配置的超时时间还未收到，那么就移除该可能发生故障的节点。实际情况下，需要考虑到因网络抖动等问题，导致正常节点被排除的情况；此外，还需要避免一些不稳定节点频繁加入或者排除的情况。为了高效的使集群保持或者重新到达一致性状态，从以下两方面来考虑问题：（1）Surrogate heartbeats（辅助心跳）：除主心跳外的心跳机制，例如，将副本写入作为辅助心跳，若副本写入完好，或者主心跳完好，可确保仅主心跳上出现的网络异常，不会影响集群视图。（2）Node Health Score（节点健康分数）：衡量节点健康情况的分数，当节点的score分数超过所有节点平均值的两倍时，则说明该节点存在异常。_（公式待补充）_
Cluster View Change：首先阐述一下集群view改变过程，当集群进入view更改周期（集群更改周期可以设置一般不宜设置太短，也不宜设置太长，太短会太频繁，太长会导致集群异常状态持续太长，请求无法处理。）时，将新增节点放在节点列表的最上面，作为paxos请求申请者，然后整个集群按照paxos算法（算法的具体过程待补充）来判断是否通过该请求，若通过则开始重新平衡数据，在请求正常通过的情况下，paoxs将花费三个网络周期时间，为了应对频繁修改view的情况，特设集群更改周期为超时时间的两倍，可以减少多次修改view状态带来的开销，多次修改可以在一个周期内完成。
Data Distribution：一个primary key通过RipeMD160算法被变成160位的摘要，摘要被分配到4096个分区空间中，分区是Aerospike中最小的数据存在单位。根据主键摘要来为记录分配分区。即使键在键空间中的分布是倾斜的，但是摘要在分配到分区空间中时是均匀的，此数据分区方案是Aerospike独有的，有助于避免在数据访问期间创建热点，实现高级别的规模和容错。as在运行读取或者查询操作时，将索引与对应的记录放在同一个节点上可以避免数据的跨节点读取，索引与数据并置，在搭配一个健壮性高的分布式hash算法，可以达到各节点数据均价分布且一致性的效果。
